\input{../preamble.tex}
\title{Eksamensdisposition - Heavy Hitters}

\begin{document}
\maketitle

\begin{itemize}
  \item \textbf{Problem}
  \item \textbf{Basic Count Sketch Algoritme}
  \item \textbf{Kvalitet af Basic Count Sketch estimatet}
  \begin{itemize}
    \item Forventet værdi
    \item Varians
    \item Afvigelse
  \end{itemize}
  \item \textbf{Median tricket og Full Count Sketch}
  \item \textbf{Count-Min Sketch Algoritme}
  \item \textbf{Kvalitet af Count-Min Sketch estimatet}
  \begin{itemize}
    \item Analyse for én tæller
    \item Analyse for flere tællere
  \end{itemize}
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Eksamensdisposition - Heavy Hitters}
% Sektion 4

\subsection{Problem}

Vi har en strøm af par $(j_0, \Delta_0), \dots, (j_{s-1}, \Delta_{s-1}) \in [n]\times \mathbb Z$ (sættet af alle heltal).

For hver eneste $j \in [n]$, lad $I_j = \{ i \in [n] \ | \ j_i = j \}$ og definer frekvensen
$$
f_j = \sum_{i \in I_j} \Delta_i
$$

Nu ønsker vi givet et $a$ at beregne et estimat $\hat f_a$ for $f_a$.

\subsection{Basic Count Sketch Algoritme}

\begin{algorithm}[H] \caption{Basic Count Sketch} \label{alg:bcs}
  \nonl Init\;
  $k = \ceil{\frac{4}{\epsilon^2}}$\;
  $C[0, \dots, k-1] = 0$\;
  $h =$ strong-universel $h : [n] \rightarrow [k]$\;
  $s =$ strong-universel $s : [n] \rightarrow \{-1, +1 \}$\;
  \nonl Process $(j, \Delta)$\;
  $C[h(j)]$ += $s(j) * \Delta$\;
  \nonl Output\;
  \Return $\hat f_a = s(a) * C[h(a)]$
\end{algorithm}\vspace{1em}

Hvor Process $(j, \Delta)$ svarer til vi løbende kører alle par i strømmen igennem i linje 5, hvor vi potentielt kunne stoppe på et vilkårligt tidspunkt.\\

\subsection{Kvalitet af Basic Count Sketch estimatet}
Lad os fiksere en nøgle $a$ og betragte outputtet $X = \hat f_a$ for en query $a$.

For enhver nøgle $j \in [n]$, definer da indikatorvariablen $Y_j = [h(j) = h(a)]$.

Vi ser, at en nøgle $j$ bidrager til tælleren $C[h(a)]$ hvis og kun hvis $h(j) = h(a)$.

Mængden den bidrager med er den frekvens $f_j$ ganget med den tilfældige fortegn $s(j)$. Derfor:

\begin{align}
  X = \hat f_a
  &= s(a) * C[h(a)] \nonumber \\
  &= s(a) \sum_{j \in [n]} f_j \, s(j) Y_j \label{eq:sa-cha} \\
  &= f_a \, s(a) s(a) Y_a + s(a) \summ{j \in [n]\\ j \neq a} f_j \, s(j) Y_j \label{eq:split-i-to} \\
  &= f_a + s(a) \summ{j \in [n]\\ j \neq a} f_j \, s(j) Y_j \label{eq:temp-res}
\end{align}

I \cref{eq:sa-cha} benytter vi at et element kun tælles med når $Y_j = 1$.\\
I \cref{eq:split-i-to} splitter vi vores sum i to, så vi tager højde for den unikke case når $j=a$ og alle andre cases.\\
I \cref{eq:temp-res} benytter vi $s(a)s(a) = 1*1$ eller $(-1)(-1) = 1$ og $Y_a = [h(a) = h(a)] = 1$.\\


Vi kan da regne på den forventede værdi af udtrykket i sumtegnet i \cref{eq:temp-res}:
\begin{align}
  \E{f_j \, s(j) Y_j}
  = f_j \ \underbrace{\E{s(j)}}_{0} \ \E{Y_j}
  = 0 \label{eq:exp-x}
\end{align}

Hvor forventningen af produktet er lig produktet af de forskellige forventninger da $s$ er 2-uafhængig, og $s$ og $h$ er uafhængige af hinanden.\\

Da kan vi bruge \cref{eq:exp-x} til at regne videre på \cref{eq:temp-res} hvorved vi får:
\begin{align}
  \E{X}
  = f_a + s(a) \summ{j \in [n]\\ j \neq a} \E{f_j \, s(j) Y_j}
  = f_a
\end{align}

Hermed har vi altså vist at $X = \hat f_a$ er en unbiased estimator for frekvensen $f_a$. Men vi skal stadig vise at det er usandsynligt den afviger for meget fra dens forventede værdi.\\


Derfor analyserer vi dens varians:
\begin{align*}
  \Var{X}
  &= \E{(\hat f_a - f_a)^2}\\
  &= \E{\pbigg{ f_a + s(a) \summ{j \in [n]\\ j \neq a} f_j \, s(j) Y_j - f_a}^2 }\\
  &= \E{\pbigg{ s(a) \summ{j \in [n]\\ j \neq a} f_j \, s(j) Y_j }^2 }\\
  &= \underbrace{(s(a))^2}_{1} \ \summ{i, j \in [n]\\i \neq a, \; j \neq a} \E{ f_i f_j s(i) s(j) Y_i Y_j }
\end{align*}

Vi bruger nu, at $h$ er stærk universel, så for ethvert $j \in [n]$ hvor $j \neq a$ har vi:
$$
\E{Y_j^2} = \E{Y_j} = \P{h(j) = h(a)} = \frac{1}{k}
$$
da $Y_j = 0 \lor 1$ og vi har $0^2 = 0$ og $1^2 = 1$.\\

Hvis vi kigger på udtrykket i summen, så har vi:
$$
\E{ f_i f_j s(i) s(j) Y_i Y_j } =
\begin{cases}
	f_j^2 \underbrace{(s(j))^2}_{1} \underbrace{\E{Y_j^2}}_{\E{Y_j}} = f_j^2 / k & i = j\\
  f_i f_j \underbrace{\E{s(i)}}_{0} \underbrace{\E{s(j)}}_{0} \E{Y_i Y_j} = 0 & i \neq j
\end{cases}
$$

Vi definerer $\sum_{j \in [n]} f_j^2 = || \mathbf f ||_2^2$ (udtales ''to-normen i anden''), hvorved vi kan regne ud vores udtryk bliver (hvor $|| \mathbf f_{-a} ||_2^2 = || \mathbf f ||_2^2 - f_a^2$.):
$$
\Var{X} = \summ{j \in [n]\\ j \neq a} \frac{f_j^2}{k} = \frac{|| \mathbf f_{-a} ||_2^2}{k}
$$

Med vores informationer for forventning og varians kan vi nu benytte Chebyshev:
$$
\P{|\hat f_a - f_a| \geq \epsilon || \mathbf f_{-a} ||_2}
\leq \frac{\Var{X}}{\epsilon^2 ||\mathbf f_{-a}||_2^2}
= \frac{1}{k \epsilon^2}
\leq \frac{1}{4}
$$
Idet vi satte $k = \ceil{4 / \epsilon^2}$ i vores algoritme.


\subsection{Median tricket}
Vi laver $t$ uafhængige estimater $X_0, \dots, X_{t-1}$ i parallel (ved at bruge forskellige hashfunktioner) og returnerer medianen $X_{(\ceil{t/2})}$ af de $t$ svar (Tal om hvad man skulle ændre i algoritmen. Denne algoritme kaldes ofte ''Final Count Sketch'').\\

Vi siger $X_i$ fejler hvis $|X_i - \E{X}| \geq Q$, hvor $Q$ f.eks. er vores sandsynlighed fra før.\\
Lad $B_i = [X_i \text{ fejler}]$ og lad $B$ være antallet der fejler:
$$
B = \sum_{i \in [t]} B_i
$$


Da har vi, at hvis $X_{(\ceil{t/2})}$ fejler, så betyder det at $B \geq t/2$.\\
Den forventede værdi af $B$ må være
$$
\E{B} = \mu = \sum_{i \in [t]} \E{B_i} \leq t/4
$$

Da kan vi beregne:
$$
\P{\text{Median fejler}}
= \P{B \geq 2 \mu}
= \P{B \geq (1 + \delta) \mu }
\leq e^{- \delta^2 \mu / 3}
\leq e^{-t/12}
$$

Hvor vi bruger Chernoff Bounds til at begrænse sandsynligheden, og herudover i eksponentialet benytter $\delta = 1$.\\

Herved har vi altså væsentligt begrænset sandsynligheden for at få noget rimelig forkert.

\subsection{Count-Min Sketch}
Vi har næsten samme problem som før, med den forskel at vi antager at der for hvert par $(j, \Delta)$ i strømmen gælder $\Delta > 0$.

\begin{algorithm}[H] \caption{Count-Min Sketch} \label{alg:count-min}
  \nonl Init\;
  $k = \ceil{\frac{2}{\epsilon}}$\;
  \BlankLine
  $t = \ceil{\lg \frac{1}{\delta}}$\;
  \BlankLine
  \For{$i \in [t]$}{
    $C_i [0, \dots, k-1] = 0$\;
    $h_i =$ strong-universel $h : [n] \rightarrow [k]$\;
  }
  \nonl Process $(j, \Delta)$\;
  \For{$i \in [t]$}{
    $C_i [h_i(j)]$ += $\Delta$
  }
  \nonl Output\;
  \Return $\hat f_a = \min_{i \in [t]} C_i [h_i(a)]$
\end{algorithm}\vspace{1em}

\subsection{Kvalitet af Count-Min Sketch estimatet}

Vi ser tydeligt at enhver tæller $C_i[h_i(a)]$ korresponderende til en nøgle $a$ er et overestimat af $f_a$. Derfor vil vi altid have:
$$
f_a \leq \hat f_a
$$

For en fikseret $a$ analyserer vi nu overskuddet i én tæller, lad os sige $C_i[h_i(a)]$. Lad den stokastiske variabel $X_i$ beskrive dette overskud. For $j \in [n]$ hvor $j \neq a$ lader vi $Y_{i,j} = [h_i(j) = h_i(a)]$. Bemærk at $j$ bidrager til tælleren hvis og kun hvis $Y_{i,j} = 1$ og når det gør er bidraget $f_j$. Således
$$
  X_i = \summ{j \in [n]\\ j \neq a} f_j Y_{i,j}
$$


På grund af $h_i$ er stærk universel er $\E{Y_{i,j} = 1/k}$. Således får vi ved linearity of expectation:
$$
  \E{X_i}
  = \summ{j \in [n]\\ j \neq a} \frac{f_j}{k}
  = \frac{||\mathbf f||_1 - f_a}{k}
  = \frac{||\mathbf f_{-a}||_1}{k}
$$

Siden alle $f_j \geq 0$ har vi $X_i \geq 0$, og kan derfor bruge Markovs ulighed til at få:
$$
  \P{X_i \geq \epsilon ||\mathbf f_{-a}||_1}
  \leq \frac{\E{X_i}}{\epsilon ||\mathbf f_{-a}||_1}
  = \frac{1}{k \epsilon}
  = \frac{1}{2}
$$
pga. vores valg af $k$ i algoritmen.

\subsection{Flere tællere}
Ovenstående sandsynlighed er for én tæller. Vi har $t$ tællere som er uafhængige. Overskuddet i outputtet, $\hat f_a - f_a$, er minimum af overskuddet for alle $X_i$ hvor $i \in [t]$. Derfor får vi:

\begin{align}
  \P{\hat f_a - f_a \geq \epsilon ||\mathbf f_{-a}||_1}
  &= \P{\min\{X_1, \dots, X_t\} \geq \epsilon ||\mathbf f_{-a}||_1}\\
  &= \P{\forall i \in [t] \text{ gælder } X_i \geq \epsilon ||\mathbf f_{-a}||_1}\\
  &= \prod_{i=1}^t \P{X_i \geq \epsilon ||\mathbf f_{-a}||_1}\\
  &\leq \frac{1}{2^t}
\end{align}

Med vores valg af $t$ i algoritmen bliver denne sandsynlighed højest $\delta$. Derfor har vi vist at der med høj sandsynlighed gælder:
$$
  f_a \leq \hat f_a \leq f_a + \epsilon ||\mathbf f_{-a}||_1
$$
hvor uligheden til venstre altid holder, og den højre ulighed fejler med sandsynligheden højest $\delta$.


\end{document}
